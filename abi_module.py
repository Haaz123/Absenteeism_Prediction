# -*- coding: utf-8 -*-
"""abi_module.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x5cQyeRh15TrWfGYkqcdmK_STDrbjXpY
"""

import numpy as np 
import pandas as pd 
import pickle
from sklearn.preprocessing import StandardScaler
from sklearn.base import BaseEstimator, TransformerMixin



# Custom scaler 
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler

class MyScaler(BaseEstimator,TransformerMixin):
    def __init__(self,columns,with_mean=True,with_std=True,copy=True):
        self.scaler = StandardScaler(copy,with_mean,with_std)
        self.columns = columns
        self.mean_ = None
        self.var_ = None

    def fit(self,X,y=None):
        self.scaler.fit(X[self.columns],y)
        self.mean_ = np.array(np.mean(X[self.columns]))
        self.var_ = np.array(np.var(X[self.columns]))
        return self

    def transform(self,X,y=None,copy=None):
        initial_col_order = X.columns
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]),columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        return pd.concat([X_not_scaled,X_scaled],axis=1)[initial_col_order]

class absent_model():

  def __init__(self, model_file, scaler_file):
    with open('model' , 'rb') as model_file, open('Scaler', 'rb') as scaler_file:
      self.reg = pickle.load(model_file)
      self.scaler = pickle.load(scaler_file)
      self.data = None

  def load_and_clean_data(self, data_file):
    #Import the data
    df= pd.read_csv(data_file, delimiter=',') 
    # store the data
    self.df_with_prediction = df.copy()
    #drop the ID column
    df = df.drop(['ID'], axis= 1)
    # add a column Absentieesm in Hours
    df['Absenteeism Time in Hours'] ='NaN'

    reason_columns= pd.get_dummies(df['Reason for Absence'], drop_first= True)

    # split reason column into 4 
    reason_type1 = reason_columns.loc[:, 1:14].max(axis=1)
    reason_type2 = reason_columns.loc[:, 15:17].max(axis=1)
    reason_type3 = reason_columns.loc[:, 18:21].max(axis=1)
    reason_type4 = reason_columns.loc[:, 22:].max(axis=1)

    #drop reason columns
    df  = df.drop(['Reason for Absence'], axis=1)
    df = pd.concat([ reason_type1, reason_type2, reason_type3, reason_type4, df], axis = 1)
    
    columns_names = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',
       'Daily Work Load Average', 'Body Mass Index', 'Education',
       'Children', 'Pets', 'Absenteeism Time in Hours']
    
    df.columns= columns_names

    # lets reorder incase

    columns_names_reorder = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',
       'Daily Work Load Average', 'Body Mass Index', 'Education',
       'Children', 'Pets', 'Absenteeism Time in Hours']

    df = df[columns_names_reorder]

    df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')

    month_list = [] 
    #year_list = []
    day_list = []


    for i in range(df.shape[0]): 
      month_list.append(df['Date'][i].month)
      day_list.append(df['Date'][i].weekday())
      #year_list.append(df_reason_mod['Date'][i].year)
      
    df['Day of the Week'] = day_list 
    df['Month of Year'] = month_list

    df= df.drop(['Date'], axis= 1) # now lets drop date section as we do not need it

      #lets update col names
    columns_names_upd = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Transportation Expense', 'Distance to Work', 'Age',
       'Daily Work Load Average', 'Body Mass Index', 'Education',
       'Children', 'Pets', 'Day of the Week', 'Month of Year', 'Absenteeism Time in Hours']

    df = df[columns_names_upd]

       #map education 

    df['Education'] = df['Education'].map({1:0, 2:1, 3:1, 4:1})
        #fill all NaN values
    df= df.fillna(value=0)

    df= df.drop(['Absenteeism Time in Hours'], axis =1)

    df = df.drop(['Distance to Work', 'Daily Work Load Average','Day of the Week'], axis =1)

    #lets make a copy of the data
    self.prepocessed_data = df.copy()

    self.data = self.scaler.transform(df)


  def predicted_prbability(self):
    if (self.data is not None):
      pred = self.reg.predict_proba(self.data)[:,1]
      return pred

  def predicted_output_category(self):
    if (self.data is not None):
      pred_outputs = self.reg.predict(self.data)
      return pred_outputs

  def predicted_outputs(self):
    if (self.data is not None):
      self.preprocessed_data['Probability'] = self.reg.predict_proba(self.data)[:,1]
      self.prepocessed_data['Prediction'] = self.reg.predict(self.data)
      return self.preprocessed_data





